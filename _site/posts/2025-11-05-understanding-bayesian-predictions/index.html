<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Stefan Schreiber">
<meta name="dcterms.date" content="2025-11-05">

<title>Understanding Bayesian Predictions ‚Äì Quantitative Environmental Services</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../images/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-e83117e711fad372bcb8c8022997a9a8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">

<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Understanding Bayesian Predictions ‚Äì Quantitative Environmental Services">
<meta property="og:description" content="From Complex MCMC Algorithms to Simple Matrix Arithmetic">
<meta property="og:image" content="https://www.envirostats.ca/posts/2025-11-05-understanding-bayesian-predictions/bayesian_prediction.png">
<meta property="og:site_name" content="Quantitative Environmental Services">
<meta property="og:image:height" content="1024">
<meta property="og:image:width" content="1536">
<meta property="og:image:alt" content="Bayesian Prediction">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../images/favicon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Quantitative Environmental Services</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../mission.html"> 
<span class="menu-text">Our Mission</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../services.html"> 
<span class="menu-text">Our Services</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Who we are</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Insights</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-core-insight" id="toc-the-core-insight" class="nav-link active" data-scroll-target="#the-core-insight">The Core Insight</a></li>
  <li><a href="#why-is-the-hard-part-hard" id="toc-why-is-the-hard-part-hard" class="nav-link" data-scroll-target="#why-is-the-hard-part-hard">Why is the hard part hard?</a>
  <ul class="collapse">
  <li><a href="#the-goal-a-joint-probability-over-all-parameters" id="toc-the-goal-a-joint-probability-over-all-parameters" class="nav-link" data-scroll-target="#the-goal-a-joint-probability-over-all-parameters">The goal: A joint probability over all parameters!</a></li>
  <li><a href="#starting-simple-grid-approximation" id="toc-starting-simple-grid-approximation" class="nav-link" data-scroll-target="#starting-simple-grid-approximation">Starting simple: Grid approximation</a></li>
  <li><a href="#the-curse-of-dimensionality-and-continuity" id="toc-the-curse-of-dimensionality-and-continuity" class="nav-link" data-scroll-target="#the-curse-of-dimensionality-and-continuity">The curse of dimensionality (and continuity)</a></li>
  <li><a href="#the-solution-mcmc-explores-the-joint-probability-space" id="toc-the-solution-mcmc-explores-the-joint-probability-space" class="nav-link" data-scroll-target="#the-solution-mcmc-explores-the-joint-probability-space">The solution: MCMC explores the joint probability space</a></li>
  </ul></li>
  <li><a href="#a-simple-example-the-matrix-structure" id="toc-a-simple-example-the-matrix-structure" class="nav-link" data-scroll-target="#a-simple-example-the-matrix-structure">A simple example: the matrix structure</a></li>
  <li><a href="#the-three-stages-of-bayesian-prediction" id="toc-the-three-stages-of-bayesian-prediction" class="nav-link" data-scroll-target="#the-three-stages-of-bayesian-prediction">The three stages of Bayesian prediction</a></li>
  <li><a href="#understanding-the-two-kinds-of-predictions" id="toc-understanding-the-two-kinds-of-predictions" class="nav-link" data-scroll-target="#understanding-the-two-kinds-of-predictions">Understanding the two kinds of predictions</a>
  <ul class="collapse">
  <li><a href="#posterior-distribution-of-the-mean-response-pmumid-d" id="toc-posterior-distribution-of-the-mean-response-pmumid-d" class="nav-link" data-scroll-target="#posterior-distribution-of-the-mean-response-pmumid-d">Posterior distribution of the mean response: <span class="math inline">\(p(\mu\mid D)\)</span></a></li>
  <li><a href="#posterior-predictive-distribution-ptildeymid-d" id="toc-posterior-predictive-distribution-ptildeymid-d" class="nav-link" data-scroll-target="#posterior-predictive-distribution-ptildeymid-d">Posterior predictive distribution: <span class="math inline">\(p(\tilde{y}\mid D)\)</span></a></li>
  <li><a href="#two-types-of-intervals-and-what-they-mean" id="toc-two-types-of-intervals-and-what-they-mean" class="nav-link" data-scroll-target="#two-types-of-intervals-and-what-they-mean">Two types of intervals (and what they mean)</a></li>
  </ul></li>
  <li><a href="#a-complete-example-with-real-tools" id="toc-a-complete-example-with-real-tools" class="nav-link" data-scroll-target="#a-complete-example-with-real-tools">A complete example with real tools</a></li>
  <li><a href="#posterior-predictive-checks-is-your-model-any-good" id="toc-posterior-predictive-checks-is-your-model-any-good" class="nav-link" data-scroll-target="#posterior-predictive-checks-is-your-model-any-good">Posterior predictive checks: Is your model any good?</a>
  <ul class="collapse">
  <li><a href="#when-ppcs-reveal-problems" id="toc-when-ppcs-reveal-problems" class="nav-link" data-scroll-target="#when-ppcs-reveal-problems">When PPCs reveal problems</a></li>
  </ul></li>
  <li><a href="#visualizing-predictions" id="toc-visualizing-predictions" class="nav-link" data-scroll-target="#visualizing-predictions">Visualizing predictions</a>
  <ul class="collapse">
  <li><a href="#what-the-figure-is-showing" id="toc-what-the-figure-is-showing" class="nav-link" data-scroll-target="#what-the-figure-is-showing">What the figure is showing</a></li>
  <li><a href="#comparing-credible-intervals-vs.-prediction-intervals" id="toc-comparing-credible-intervals-vs.-prediction-intervals" class="nav-link" data-scroll-target="#comparing-credible-intervals-vs.-prediction-intervals">Comparing credible intervals vs.&nbsp;prediction intervals</a></li>
  </ul></li>
  <li><a href="#takeaway-from-complex-to-simple" id="toc-takeaway-from-complex-to-simple" class="nav-link" data-scroll-target="#takeaway-from-complex-to-simple">Takeaway: from complex to simple</a></li>
  <li><a href="#advanced-topics" id="toc-advanced-topics" class="nav-link" data-scroll-target="#advanced-topics">Advanced Topics</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading">Further reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Understanding Bayesian Predictions</h1>
<p class="subtitle lead">From Complex MCMC Algorithms to Simple Matrix Arithmetic</p>
  <div class="quarto-categories">
    <div class="quarto-category">bayesian</div>
    <div class="quarto-category">prediction</div>
    <div class="quarto-category">inference</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Stefan Schreiber </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 5, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="bayesian_prediction.png" class="img-fluid figure-img"></p>
<figcaption>From uncertainty, form arises ‚Äî the flow from belief to prediction.</figcaption>
</figure>
</div>
<p>So you‚Äôve just fit your first Bayesian model using <code>brms</code> or <code>rstanarm</code>. Maybe you were surprised by how easy it was ‚Äì the syntax looked almost exactly like <code>lm()</code> for a simple linear regression. You hit run, waited a bit longer than usual, and got‚Ä¶ output. Lots of output.</p>
<p>You look at the summary. There are means and standard deviations, credible intervals, and mysterious diagnostics like ‚ÄúRhat‚Äù and ‚ÄúESS‚Äù. But wait ‚Äì where are the p-values üòú And how do you actually make predictions? People keep talking about ‚Äúposterior predictions‚Äù and ‚Äúposterior distributions‚Äù ‚Äì what do those actually mean, and how do you work with them?</p>
<p>If you‚Äôve ever felt confused by the terminology around Bayesian predictions ‚Äì posterior predictive distributions, expected predictions, prediction intervals ‚Äì you‚Äôre not alone. But here‚Äôs the secret: once your Bayesian model calculates the posterior distribution, <strong>everything else is just computing means, quantiles, and other summary statistics</strong>. Let me show you what I mean.</p>
<blockquote class="blockquote">
<p><strong>Note:</strong> All examples in this post were built using R with the <code>rstanarm</code>, <code>tidybayes</code>, and <code>ggplot2</code> packages. You can follow along by copying and pasting the code ‚Äì everything is self-contained and reproducible. We‚Äôll focus primarily on Normal (Gaussian) linear models throughout this post, though the workflow applies to all model families (see the Advanced Topics section at the end for important details about non-linear models).</p>
</blockquote>
<section id="the-core-insight" class="level2">
<h2 class="anchored" data-anchor-id="the-core-insight">The Core Insight</h2>
<p>Bayesian inference has two phases:</p>
<ol type="1">
<li><strong>The hard part</strong>: Computing the posterior distribution <span class="math inline">\(p(\theta\mid D)\)</span> (this is where MCMC comes in).</li>
<li><strong>The easy part</strong>: Summarizing that posterior and quantities derived from it ‚Äì means, standard deviations, quantiles, etc.</li>
</ol>
<p>Once you have posterior samples from <span class="math inline">\(p(\theta\mid D)\)</span>, you can generate:</p>
<ul>
<li>the posterior distribution of the mean response <span class="math inline">\(p(\mu\mid D)\)</span></li>
<li>the posterior predictive distribution <span class="math inline">\(p(\tilde{y}\mid D)\)</span></li>
</ul>
<p>and then summarize these distributions in various ways: means (expectations) like <span class="math inline">\(E[\tilde{y}\mid D]\)</span>, medians, quantiles for intervals, etc.</p>
</section>
<section id="why-is-the-hard-part-hard" class="level2">
<h2 class="anchored" data-anchor-id="why-is-the-hard-part-hard">Why is the hard part hard?</h2>
<p>Before the ‚Äúeasy part‚Äù, a quick sketch of why computing the posterior is challenging (you don‚Äôt have to master this to <em>use</em> Bayesian methods, but the intuition helps).</p>
<section id="the-goal-a-joint-probability-over-all-parameters" class="level3">
<h3 class="anchored" data-anchor-id="the-goal-a-joint-probability-over-all-parameters">The goal: A joint probability over all parameters!</h3>
<p>Bayes‚Äô theorem:</p>
<p><span class="math display">\[
p(\theta \mid D) \;=\; \frac{p(D \mid \theta)\,p(\theta)}{p(D)}
\]</span></p>
<ul>
<li><span class="math inline">\(p(\theta \mid D)\)</span>: <strong>posterior</strong> ‚Äì what we believe about parameters after seeing data<br>
</li>
<li><span class="math inline">\(p(D \mid \theta)\)</span>: <strong>likelihood</strong> ‚Äì how well parameters explain the data<br>
</li>
<li><span class="math inline">\(p(\theta)\)</span>: <strong>prior</strong> ‚Äì what we believed before seeing data<br>
</li>
<li><span class="math inline">\(p(D)\)</span>: <strong>marginal likelihood / evidence</strong> ‚Äì a normalizing constant</li>
</ul>
<p>Because <span class="math inline">\(p(D)\)</span> is often intractable, we work with <span class="math inline">\(p(\theta \mid D) \propto p(D \mid \theta)\, p(\theta)\)</span>. For a simple regression with parameters <span class="math inline">\(\alpha,\beta,\sigma\)</span>:</p>
<p><span class="math display">\[
p(\alpha,\beta,\sigma \mid D) \propto p(D \mid \alpha,\beta,\sigma)\, p(\alpha,\beta,\sigma).
\]</span></p>
<p>This is a joint distribution in a high-dimensional space. More parameters ‚áí higher dimension.</p>
</section>
<section id="starting-simple-grid-approximation" class="level3">
<h3 class="anchored" data-anchor-id="starting-simple-grid-approximation">Starting simple: Grid approximation</h3>
<p>You‚Äôre a fish biologist studying the hatching rate, denoted by <span class="math inline">\(\theta\)</span>, of rainbow trout. In an experiment, <strong>4 out of 10 eggs hatched</strong>.</p>
<p>Instead of chasing a single ‚Äúbest‚Äù estimate, we want the <strong>entire posterior distribution</strong> of plausible hatching rates given both our data and prior beliefs. This is the key idea in Bayesian inference ‚Äì we quantify <em>uncertainty</em> rather than ignore it.</p>
<p>To make this concrete, we use a <strong>grid approximation</strong>. We choose a fine grid of possible hatching rates, <span class="math display">\[
\theta \in [0, 1],
\]</span> meaning <span class="math inline">\(\theta\)</span> can take any value between 0 (no eggs hatch) and 1 (all eggs hatch).</p>
<p>For each possible value of <span class="math inline">\(\theta\)</span>, we compute how likely it is to observe 4 hatched eggs out of 10, multiply that by the prior belief about <span class="math inline">\(\theta\)</span>, and normalize so the probabilities sum to one.</p>
<p>The result is a <strong>posterior distribution</strong> over <span class="math inline">\(\theta\)</span>: it shows not just which hatching rate is most plausible, but how confident we are about different possibilities ‚Äì allowing us to summarize uncertainty with quantities like the posterior mean, median, mode (MAP), or credible intervals.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a grid of possible hatching rates from 0 to 1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>theta_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior options:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>prior_flat <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>)                        <span class="co"># Uninformative (flat)</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>prior_conservative <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta_grid, <span class="dv">5</span>, <span class="dv">5</span>)    <span class="co"># Moderate rates likely</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>prior_optimistic <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta_grid, <span class="dv">8</span>, <span class="dv">2</span>)      <span class="co"># High rates likely</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>prior_skeptical <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta_grid, <span class="dv">2</span>, <span class="dv">8</span>)       <span class="co"># Low rates likely</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># üëâ CHANGE THIS LINE to try different priors:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> prior_flat   </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood: how likely is observing 4/10 for each possible Œ∏?</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed data: 4 hatched out of 10 eggs</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>successes <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>trials <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>observed_rate <span class="ot">&lt;-</span> successes <span class="sc">/</span> trials</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(successes, <span class="at">size =</span> trials, <span class="at">prob =</span> theta_grid)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior ‚àù Likelihood √ó Prior, then normalize</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the posterior distribution</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">theta =</span> theta_grid, <span class="at">posterior =</span> posterior) <span class="sc">|&gt;</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Dashed red line = observed rate (from data), stays fixed</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Shows how different priors shift the posterior relative to observed data</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> observed_rate, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Hatching rate (Œ∏)"</span>,</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Posterior probability"</span>,</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Posterior distribution with 100 grid points"</span>) <span class="sc">+</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/grid-approximation-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Try changing the prior (e.g., <code>prior_conservative</code>, <code>prior_optimistic</code>, or <code>prior_skeptical</code>) and re-running the code to see how different prior beliefs influence the posterior. This highlights one of the most important insights in Bayesian inference ‚Äì <strong>the posterior reflects both the data and the prior assumptions</strong>.</p>
<p><strong>Quick tie-in:</strong> From this posterior <span class="math inline">\(p(\theta\mid D)\)</span>, we can generate a posterior predictive distribution <span class="math inline">\(p(\tilde{y}\mid D)\)</span> (e.g., future hatch counts) and summarize it using statistics like the mean <span class="math inline">\(E[\tilde{y}\mid D]\)</span>, median, or credible intervals.</p>
</section>
<section id="the-curse-of-dimensionality-and-continuity" class="level3">
<h3 class="anchored" data-anchor-id="the-curse-of-dimensionality-and-continuity">The curse of dimensionality (and continuity)</h3>
<p>The grid approach worked because we only had one parameter to explore. But once we add even a few more ‚Äì say a slope, an intercept, and a noise term ‚Äì the same idea breaks down. We‚Äôd need to evaluate millions of grid points just to cover the space:</p>
<ul>
<li>1 parameter, 100 grid points ‚áí 100 evaluations<br>
</li>
<li>2 parameters ‚áí <span class="math inline">\(100^2 = 10{,}000\)</span><br>
</li>
<li>3 parameters ‚áí <span class="math inline">\(100^3 = 1{,}000{,}000\)</span><br>
</li>
<li>10 parameters ‚áí <span class="math inline">\(100^{10}\)</span> (astronomical)</li>
</ul>
<p>Most parameters are also <strong>continuous</strong>, so inference involves integrals over infinitely many values. For instance, marginalizing <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
p(\alpha \mid D) \;=\; \int p(\alpha,\beta \mid D)\,d\beta.
\]</span></p>
<p>Analytical solutions exist for special conjugate cases; real-world models usually require computation.</p>
</section>
<section id="the-solution-mcmc-explores-the-joint-probability-space" class="level3">
<h3 class="anchored" data-anchor-id="the-solution-mcmc-explores-the-joint-probability-space">The solution: MCMC explores the joint probability space</h3>
<p><strong>Markov chain Monte Carlo (MCMC)</strong> avoids gridding and intractable integrals by <em>sampling</em> parameter values, spending more time in high-probability regions of the <strong>joint posterior space</strong>. After convergence and warm-up, the draws are (approximately) samples from the posterior <span class="math inline">\(p(\theta \mid D)\)</span>.</p>
<p>The result is a table of draws (rows = draws, columns = parameters). <strong>That table is the payoff.</strong> From here, we move to predictions by generating the posterior predictive distribution <span class="math inline">\(p(\tilde{y} \mid D)\)</span>, which we can then summarize with statistics such as its mean <span class="math inline">\(E[\tilde{y} \mid D]\)</span>, median, or quantiles.</p>
</section>
</section>
<section id="a-simple-example-the-matrix-structure" class="level2">
<h2 class="anchored" data-anchor-id="a-simple-example-the-matrix-structure">A simple example: the matrix structure</h2>
<p>Now, how do posterior <strong>parameter</strong> draws become <strong>predictions</strong>? Think in matrices.</p>
<p>Each column corresponds to one posterior draw of <span class="math inline">\((\alpha,\beta,\sigma)\)</span>. For each draw and each observation <span class="math inline">\(i\)</span>, compute the linear predictor <span class="math inline">\(\mu_i = \alpha + \beta x_i\)</span>. Stack those <span class="math inline">\(\mu\)</span> values into a matrix: rows = observations, columns = draws.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># IMPORTANT: This uses only 3 draws for illustration.</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Real analyses use 1,000‚Äì4,000+ draws.</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>predicted_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fl">2.0</span>, <span class="fl">2.1</span>, <span class="fl">1.9</span>,  <span class="co"># Obs 1: Œº‚ÇÅ from posterior draws 1, 2, 3</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fl">1.0</span>, <span class="fl">1.2</span>, <span class="fl">1.1</span>,  <span class="co"># Obs 2: Œº‚ÇÇ from posterior draws 1, 2, 3</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fl">4.0</span>, <span class="fl">3.8</span>, <span class="fl">4.2</span>,  <span class="co"># Obs 3: Œº‚ÇÉ from posterior draws 1, 2, 3</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fl">1.0</span>, <span class="fl">1.1</span>, <span class="fl">0.9</span>   <span class="co"># Obs 4: Œº‚ÇÑ from posterior draws 1, 2, 3</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>), <span class="at">nrow =</span> <span class="dv">4</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(predicted_matrix) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Obs 1"</span>, <span class="st">"Obs 2"</span>, <span class="st">"Obs 3"</span>, <span class="st">"Obs 4"</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(predicted_matrix) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Draw 1"</span>, <span class="st">"Draw 2"</span>, <span class="st">"Draw 3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Connecting this to Bayesian prediction:</strong></p>
<ul>
<li>The columns come from <span class="math inline">\(p(\theta\mid D)\)</span> ‚Äì posterior samples of parameters.<br>
</li>
<li>Each row across columns represents the posterior distribution of the mean response <span class="math inline">\(p(\mu_i\mid D)\)</span> for observation <span class="math inline">\(i\)</span>.<br>
</li>
<li>Row summaries (mean, quantiles) give point estimates like <span class="math inline">\(E[\mu_i\mid D]\)</span> and credible intervals.</li>
</ul>
<p>Let‚Äôs display the matrix with row means (i.e., expected mean responses for this toy example):</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Prediction Matrix: Each row is an observation, each column is a posterior draw</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Draw 1</th>
<th style="text-align: right;">Draw 2</th>
<th style="text-align: right;">Draw 3</th>
<th style="text-align: right;">Row Mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Obs 1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2.1</td>
<td style="text-align: right;">1.9</td>
<td style="text-align: right;">2.0</td>
</tr>
<tr class="even">
<td style="text-align: left;">Obs 2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.2</td>
<td style="text-align: right;">1.1</td>
<td style="text-align: right;">1.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Obs 3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">3.8</td>
<td style="text-align: right;">4.2</td>
<td style="text-align: right;">4.0</td>
</tr>
<tr class="even">
<td style="text-align: left;">Obs 4</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.1</td>
<td style="text-align: right;">0.9</td>
<td style="text-align: right;">1.0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><br></p>
<p>Once predictions are organized this way, everything reduces to simple arithmetic across columns:</p>
<ul>
<li><strong>Mean response</strong> <span class="math inline">\(E[\mu_i\mid D]\)</span>: row means (averaging the posterior distribution of the mean response for each observation)</li>
<li><strong>Credible intervals</strong> for the <strong>mean response</strong>: rowwise quantiles of the <span class="math inline">\(\mu_i\)</span> values</li>
<li>Next we‚Äôll add <span class="math inline">\(\sigma\)</span> to generate the full posterior predictive distribution <span class="math inline">\(p(\tilde{y}\mid D)\)</span> and prediction intervals</li>
</ul>
</section>
<section id="the-three-stages-of-bayesian-prediction" class="level2">
<h2 class="anchored" data-anchor-id="the-three-stages-of-bayesian-prediction">The three stages of Bayesian prediction</h2>
<p>To pull our ideas together, here‚Äôs the compact relationship we‚Äôll now use repeatedly:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 18%">
<col style="width: 24%">
<col style="width: 28%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">Stage</th>
<th>Distribution</th>
<th>What it describes</th>
<th>Uncertainty captured</th>
<th>How we get it</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td><span class="math inline">\(p(\theta\mid D)\)</span></td>
<td>What we believe about parameters after seeing data</td>
<td><strong>Parameter</strong> uncertainty</td>
<td>MCMC sampling</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td><span class="math inline">\(p(\mu\mid D)\)</span></td>
<td>Posterior distribution of the mean response</td>
<td><strong>Parameter</strong> uncertainty (propagated to <span class="math inline">\(\mu\)</span>)</td>
<td>For each <span class="math inline">\(\theta^{(s)}\)</span>, compute <span class="math inline">\(\mu^{(s)} = \alpha^{(s)} + \beta^{(s)} x\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td><span class="math inline">\(p(\tilde{y}\mid D)\)</span></td>
<td>Posterior predictive: distribution over future observations</td>
<td><strong>Parameter + observation</strong> uncertainty</td>
<td>For each <span class="math inline">\(\mu^{(s)}\)</span>, draw <span class="math inline">\(\tilde{y}^{(s)} \sim \text{Normal}(\mu^{(s)}, \sigma^{(s)})\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td>Summaries</td>
<td>Point estimates and intervals from stage 2 or 3</td>
<td>Depends on what we summarize</td>
<td>e.g., <span class="math inline">\(E[\tilde{y}\mid D] = \frac{1}{S}\sum_s \tilde{y}^{(s)}\)</span> or quantiles</td>
</tr>
</tbody>
</table>
<p><strong>Key insight:</strong> Each stage builds on the previous one. We start with parameter draws from MCMC (stage 1), push them through our model equation to get mean responses (stage 2), add observation noise to get predictions (stage 3), and finally summarize those distributions (stage 4). Note that summaries from stage 2 will have narrower intervals than summaries from stage 3 because stage 3 includes observation noise.</p>
<p><strong>Plain language:</strong> posterior over parameters ‚áí compute expected responses ‚áí add noise to get predictions ‚áí summarize.</p>
</section>
<section id="understanding-the-two-kinds-of-predictions" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-two-kinds-of-predictions">Understanding the two kinds of predictions</h2>
<section id="posterior-distribution-of-the-mean-response-pmumid-d" class="level3">
<h3 class="anchored" data-anchor-id="posterior-distribution-of-the-mean-response-pmumid-d">Posterior distribution of the mean response: <span class="math inline">\(p(\mu\mid D)\)</span></h3>
<p><strong>The posterior distribution of the mean response:</strong> For each observation <span class="math inline">\(i\)</span> and each posterior parameter draw <span class="math inline">\(\theta^{(s)}\)</span> (where <span class="math inline">\(s\)</span> indexes the draw), we compute the mean response:</p>
<p><span class="math display">\[\mu_i^{(s)} = \alpha^{(s)} + \beta^{(s)} x_i\]</span></p>
<p>The collection of values <span class="math inline">\(\{\mu_i^{(s)}\}_{s=1}^S\)</span> represents samples from the posterior distribution of the mean response at <span class="math inline">\(x_i\)</span>. We can summarize this distribution by computing the mean across posterior draws:</p>
<p><span class="math display">\[E[\mu_i|D] = \frac{1}{S}\sum_{s=1}^S \mu_i^{(s)}\]</span></p>
<p><strong>For Normal models:</strong> Because the observation noise has mean zero, <span class="math inline">\(E[\mu_i|D] = E[\tilde{y}_i|D]\)</span>. This means we can work with <span class="math inline">\(\mu\)</span> directly without simulating full observations ‚Äì the expected value of the mean response equals the expected value of a future observation.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For each observation, compute the mean of the posterior distribution</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the mean response (i.e., mean across posterior draws)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># This gives E[Œº·µ¢|D], which equals E[·ªπ·µ¢|D] for Normal models</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>epred <span class="ot">&lt;-</span> <span class="fu">rowMeans</span>(predicted_matrix)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(epred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Obs 1 Obs 2 Obs 3 Obs 4 
  2.0   1.1   4.0   1.0 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important note about non-linear models
</div>
</div>
<div class="callout-body-container callout-body">
<p>The equality <span class="math inline">\(E[\mu_i|D] = E[\tilde{y}_i|D]\)</span> holds for Normal linear models, but <strong>breaks down for models with non-linear link functions</strong> (logistic, Poisson, etc.). For those models, always generate full posterior predictive draws first, then summarize. See the Advanced Topics section at the end of this post for details and examples.</p>
</div>
</div>
</section>
<section id="posterior-predictive-distribution-ptildeymid-d" class="level3">
<h3 class="anchored" data-anchor-id="posterior-predictive-distribution-ptildeymid-d">Posterior predictive distribution: <span class="math inline">\(p(\tilde{y}\mid D)\)</span></h3>
<p>To see the full range of plausible observations (not just the mean response), we need to add observation noise.</p>
<p><strong>The mathematical idea:</strong> The posterior predictive distribution integrates over all parameter uncertainty:</p>
<p><span class="math display">\[p(\tilde{y}\mid D) = \int p(\tilde{y}\mid \theta)\, p(\theta\mid D)\, d\theta\]</span></p>
<p><strong>How we compute it:</strong> For each posterior parameter draw <span class="math inline">\(\theta^{(s)}\)</span>:</p>
<ol type="1">
<li>Compute the mean response: <span class="math inline">\(\mu^{(s)} = \alpha^{(s)} + \beta^{(s)} x\)</span></li>
<li>Draw a new observation from the likelihood: <span class="math inline">\(\tilde{y}^{(s)} \sim p(y\mid \mu^{(s)}, \theta^{(s)})\)</span></li>
</ol>
<p>For Normal models specifically, step 2 becomes: <span class="math inline">\(\tilde{y}^{(s)} = \mu^{(s)} + \epsilon^{(s)}\)</span> where <span class="math inline">\(\epsilon^{(s)} \sim \text{Normal}(0, \sigma^{(s)})\)</span>.</p>
<p>The collection <span class="math inline">\(\{\tilde{y}^{(s)}\}_{s=1}^S\)</span> represents samples from <span class="math inline">\(p(\tilde{y}|D)\)</span>.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior draws of œÉ (one for each column)</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>sigma_draws <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.55</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate ·ªπ·µ¢ ~ Normal(Œº·µ¢, œÉ) for each draw</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>y_pred_matrix <span class="ot">&lt;-</span> predicted_matrix</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) {</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  y_pred_matrix[, j] <span class="ot">&lt;-</span> predicted_matrix[, j] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">4</span>, <span class="dv">0</span>, sigma_draws[j])</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Posterior predictive samples from p(·ªπ|D)</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Draw 1</th>
<th style="text-align: right;">Draw 2</th>
<th style="text-align: right;">Draw 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Obs 1</td>
<td style="text-align: right;">1.72</td>
<td style="text-align: right;">2.18</td>
<td style="text-align: right;">1.52</td>
</tr>
<tr class="even">
<td style="text-align: left;">Obs 2</td>
<td style="text-align: right;">0.88</td>
<td style="text-align: right;">2.23</td>
<td style="text-align: right;">0.85</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Obs 3</td>
<td style="text-align: right;">4.78</td>
<td style="text-align: right;">4.08</td>
<td style="text-align: right;">4.87</td>
</tr>
<tr class="even">
<td style="text-align: left;">Obs 4</td>
<td style="text-align: right;">1.04</td>
<td style="text-align: right;">0.34</td>
<td style="text-align: right;">1.10</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><br></p>
<p>These <span class="math inline">\(\tilde{y}\)</span> values vary more than the <span class="math inline">\(\mu\)</span> values because they include <span class="math inline">\(\sigma\)</span>: the <em>irreducible</em> variation around the mean response.</p>
</section>
<section id="two-types-of-intervals-and-what-they-mean" class="level3">
<h3 class="anchored" data-anchor-id="two-types-of-intervals-and-what-they-mean">Two types of intervals (and what they mean)</h3>
<p><strong>Credible intervals (for the mean response)</strong> ‚Äì from the <span class="math inline">\(\mu_i\)</span> matrix (parameter uncertainty only):</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(predicted_matrix, <span class="dv">1</span>, quantile, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      Obs 1 Obs 2 Obs 3 Obs 4
2.5%  1.905 1.005  3.81 0.905
97.5% 2.095 1.195  4.19 1.095</code></pre>
</div>
</div>
<p><strong>Prediction intervals (for future observations)</strong> ‚Äì from the <span class="math inline">\(\tilde{y}\)</span> matrix (parameter + observation uncertainty):</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(y_pred_matrix, <span class="dv">1</span>, quantile, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>         Obs 1     Obs 2   Obs 3     Obs 4
2.5%  1.532107 0.8563872 4.11169 0.3756778
97.5% 2.154682 2.1618326 4.86855 1.0947654</code></pre>
</div>
</div>
<p>Prediction intervals are always wider: they include both uncertainty about the mean response and the natural spread of outcomes.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Decision guide (tidybayes/R workflow)
</div>
</div>
<div class="callout-body-container callout-body">
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 12%">
<col style="width: 35%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Question</th>
<th>Use</th>
<th>What you get</th>
<th>Function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>What‚Äôs the average outcome?</td>
<td>Mean response distribution</td>
<td>distribution <span class="math inline">\(p(\mu\mid D)\)</span>; summarize to get <span class="math inline">\(E[\tilde{y}\mid D]\)</span></td>
<td><code>add_epred_draws()</code></td>
</tr>
<tr class="even">
<td>What might I observe?</td>
<td>Posterior predictive</td>
<td>distribution <span class="math inline">\(p(\tilde{y}\mid D)\)</span></td>
<td><code>add_predicted_draws()</code></td>
</tr>
<tr class="odd">
<td>Is my model realistic?</td>
<td>Posterior predictive</td>
<td>compare simulations to data</td>
<td><code>add_predicted_draws()</code></td>
</tr>
<tr class="even">
<td>What‚Äôs the effect of X?</td>
<td>Mean response distribution</td>
<td>change in <span class="math inline">\(E[\mu\mid D]\)</span></td>
<td><code>add_epred_draws()</code></td>
</tr>
<tr class="odd">
<td>Do I need prediction intervals?</td>
<td>Posterior predictive</td>
<td>full uncertainty range</td>
<td><code>add_predicted_draws()</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Mini-recap:</strong> parameters <span class="math inline">\(p(\theta\mid D)\)</span> ‚áí mean responses <span class="math inline">\(p(\mu\mid D)\)</span> ‚áí predictions <span class="math inline">\(p(\tilde{y}\mid D)\)</span> ‚áí summaries like <span class="math inline">\(E[\tilde{y}\mid D]\)</span>.</p>
</section>
</section>
<section id="a-complete-example-with-real-tools" class="level2">
<h2 class="anchored" data-anchor-id="a-complete-example-with-real-tools">A complete example with real tools</h2>
<p>Let‚Äôs fit a model with <code>rstanarm</code> using default priors (see <code>help('prior_summary')</code> for more details) and inspect the output.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstanarm)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidybayes)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate some data: y = 2 + 0.5x + noise</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Bayesian regression (MCMC to get posterior samples)</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>                <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">iter =</span> <span class="dv">2000</span>,</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>                <span class="at">refresh =</span> <span class="dv">0</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Model Info:
 function:     stan_glm
 family:       gaussian [identity]
 formula:      y ~ x
 algorithm:    sampling
 sample:       4000 (posterior sample size)
 priors:       see help('prior_summary')
 observations: 100
 predictors:   2

Estimates:
              mean   sd   10%   50%   90%
(Intercept) 1.9    0.1  1.8   1.9   2.0  
x           0.4    0.1  0.3   0.4   0.6  
sigma       1.0    0.1  0.9   1.0   1.1  

Fit Diagnostics:
           mean   sd   10%   50%   90%
mean_PPD 1.9    0.1  1.8   1.9   2.1  

The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).

MCMC diagnostics
              mcse Rhat n_eff
(Intercept)   0.0  1.0  3751 
x             0.0  1.0  3770 
sigma         0.0  1.0  3506 
mean_PPD      0.0  1.0  4125 
log-posterior 0.0  1.0  1789 

For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding the output
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Model Info</strong> (top):</p>
<ul>
<li><code>function: stan_glm</code> ‚Äì we‚Äôre using Stan‚Äôs generalized linear model</li>
<li><code>family: gaussian [identity]</code> ‚Äì Normal distribution with identity link (standard linear regression)</li>
<li><code>sample: 4000</code> ‚Äì we have 4000 posterior draws (4 chains √ó 2000 iterations, after warmup)</li>
<li><code>observations: 100, predictors: 2</code> ‚Äì confirms our data structure (intercept + x)</li>
</ul>
<p><strong>Estimates table</strong>:</p>
<ul>
<li><code>(Intercept)</code>: mean = 1.9 (we simulated with 2.0) ‚úì</li>
<li><code>x</code>: mean = 0.4 (we simulated with 0.5) ‚úì</li>
<li><code>sigma</code>: mean = 1.0 (we simulated with sd = 1) ‚úì</li>
</ul>
<p>The model recovered our true parameters! The <code>sd</code> column shows posterior uncertainty ‚Äì how much each parameter varies across draws. The percentiles (10%, 50%, 90%) give you credible intervals.</p>
<p><strong>MCMC Diagnostics</strong> (bottom table):</p>
<ul>
<li><code>Rhat = 1.0</code> for all parameters ‚Üí chains converged ‚úì</li>
<li><code>n_eff &gt; 1700</code> for all ‚Üí plenty of effective samples ‚úì</li>
</ul>
<p>These diagnostics tell us we can trust our posterior samples. Always check these before using your model!</p>
<p><strong>The key insight</strong>: This summary is just describing <em>columns</em> of the posterior draws matrix. Each parameter gets one row showing its column mean, column SD, and column quantiles. After MCMC does the hard work, everything else is simple arithmetic on those columns.</p>
</div>
</div>
<p>Now let‚Äôs check if this model is any good before using it for predictions.</p>
</section>
<section id="posterior-predictive-checks-is-your-model-any-good" class="level2">
<h2 class="anchored" data-anchor-id="posterior-predictive-checks-is-your-model-any-good">Posterior predictive checks: Is your model any good?</h2>
<p>Before we use our model for predictions, we should check: <strong>does data simulated from our model look like our actual data?</strong> If not, our model is missing something important.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayesplot)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract posterior predictive samples</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>y_rep <span class="ot">&lt;-</span> <span class="fu">posterior_predict</span>(fit)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare distribution of observed vs. simulated data</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ppc_dens_overlay</span>(y, y_rep[<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>, ]) <span class="sc">+</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Posterior predictive check: Density comparison"</span>,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Light blue = 100 draws from p(·ªπ|D), Dark blue = observed data"</span>) <span class="sc">+</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/ppc-visual-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>What to look for:</strong> Do the light blue curves (simulated data) cover the dark blue curve (observed data)? If observed data looks like ‚Äújust another draw‚Äù from the model, that‚Äôs good. If it‚Äôs systematically different (e.g., observed has heavier tails, bimodality, etc.), your model may need revision.</p>
<p><strong>In our case:</strong> The simulated data (light blue curves) nicely envelope the observed data (dark blue), suggesting our Normal linear model with constant variance is reasonable for this dataset.</p>
<section id="when-ppcs-reveal-problems" class="level3">
<h3 class="anchored" data-anchor-id="when-ppcs-reveal-problems">When PPCs reveal problems</h3>
<p>If posterior predictive checks fail, common issues include:</p>
<ul>
<li><strong>Outliers not captured</strong>: Consider robust likelihoods (Student-t instead of Normal)</li>
<li><strong>Non-constant variance</strong>: Add variance modeling (e.g., <code>sigma ~ x</code>)</li>
<li><strong>Non-linearity missed</strong>: Add polynomial terms or smooths</li>
<li><strong>Clustering ignored</strong>: Consider hierarchical/mixed models</li>
</ul>
</section>
</section>
<section id="visualizing-predictions" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-predictions">Visualizing predictions</h2>
<p>Now that we‚Äôve validated our model, let‚Äôs see both types of predictions in action. Remember: <code>add_epred_draws()</code> gives you the <strong>posterior distribution of the mean response</strong> <span class="math inline">\(p(\mu|D)\)</span>, while <code>add_predicted_draws()</code> gives you the <strong>posterior predictive distribution</strong> <span class="math inline">\(p(\tilde{y}|D)\)</span> (mean response plus observation noise). Both are distributions that we then summarize with statistics like means, medians, or quantiles.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we can extract both types of predictions:</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># - add_epred_draws(): posterior distribution of mean response p(Œº|D)</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># - add_predicted_draws(): posterior predictive distribution p(·ªπ|D)</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's visualize both simultaneously:</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>data <span class="sc">|&gt;</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_epred_draws</span>(fit) <span class="sc">|&gt;</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Blue bands: credible intervals for E[Œº|D]</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_lineribbon</span>(<span class="fu">aes</span>(<span class="at">y =</span> .epred), <span class="at">.width =</span> <span class="fu">c</span>(<span class="fl">0.61</span>, <span class="fl">0.89</span>)) <span class="sc">+</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Black points: observed data</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> data, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Red points: 50 samples from p(·ªπ|D) showing full predictive distribution</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> data <span class="sc">|&gt;</span> <span class="fu">add_predicted_draws</span>(fit) <span class="sc">|&gt;</span> <span class="fu">sample_draws</span>(<span class="dv">50</span>),</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>             <span class="fu">aes</span>(<span class="at">y =</span> .prediction),</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">alpha =</span> <span class="fl">0.15</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_brewer</span>() <span class="sc">+</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Expected predictions (blue) vs. Posterior predictions (red)"</span>,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Blue bands: E[Œº|D] credible intervals; Red: samples from p(·ªπ|D)"</span>,</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">caption =</span> <span class="st">"Black = observed data | Blue = credible intervals for mean response | Red = posterior prediction samples"</span>) <span class="sc">+</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/visualize-predictions-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="what-the-figure-is-showing" class="level3">
<h3 class="anchored" data-anchor-id="what-the-figure-is-showing">What the figure is showing</h3>
<ul>
<li><strong>Black points</strong>: observed data<br>
</li>
<li><strong>Blue bands</strong>: credible intervals for the posterior distribution of the mean response <span class="math inline">\(p(\mu\mid D)\)</span>. Each band shows where the expected response is likely to be; the center line represents <span class="math inline">\(E[\mu\mid D]\)</span> which equals <span class="math inline">\(E[\tilde{y}\mid D]\)</span> for Normal models.</li>
<li><strong>Red points</strong>: samples from the posterior predictive distribution <span class="math inline">\(p(\tilde{y}\mid D)\)</span> ‚Äì plausible observations that include observation noise <span class="math inline">\(\sigma\)</span></li>
</ul>
<p>Why are the red points more dispersed? They include <span class="math inline">\(\sigma\)</span>, the irreducible variation around the mean response. If you re-ran the same study, new observations would scatter around the blue line much like those red points.</p>
</section>
<section id="comparing-credible-intervals-vs.-prediction-intervals" class="level3">
<h3 class="anchored" data-anchor-id="comparing-credible-intervals-vs.-prediction-intervals">Comparing credible intervals vs.&nbsp;prediction intervals</h3>
<p>The plot above shows both types of uncertainty, but let‚Äôs make the distinction even clearer with a direct comparison:</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create new data for prediction</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">50</span>))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get both types of intervals</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>epred_intervals <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_epred_draws</span>(fit) <span class="sc">|&gt;</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">median_qi</span>(.epred, <span class="at">.width =</span> <span class="fl">0.89</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>pred_intervals <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_predicted_draws</span>(fit) <span class="sc">|&gt;</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">median_qi</span>(.prediction, <span class="at">.width =</span> <span class="fl">0.89</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot credible intervals (for mean response)</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(epred_intervals, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> .epred)) <span class="sc">+</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> .lower, <span class="at">ymax =</span> .upper), <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">fill =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"89% Credible Intervals for E[Œº|D]"</span>,</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Where we expect the mean response to be"</span>,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"y"</span>) <span class="sc">+</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">6</span>))</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot prediction intervals (for observations)</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(pred_intervals, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> .prediction)) <span class="sc">+</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> .lower, <span class="at">ymax =</span> .upper), <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">fill =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"89% Prediction Intervals for p(·ªπ|D)"</span>,</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Where we expect future observations to fall"</span>,</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"y"</span>) <span class="sc">+</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">6</span>))</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">+</span> p2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/interval-comparison-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key insight:</strong> Both plots show the same fitted line, but:</p>
<ul>
<li><p><strong>Left (blue)</strong>: Narrow bands showing uncertainty about the <em>average</em> relationship. ‚ÄúIf I could repeat this experiment infinite times, where would the mean response at each <span class="math inline">\(x\)</span> value fall?‚Äù</p></li>
<li><p><strong>Right (red)</strong>: Wide bands showing uncertainty about <em>individual observations</em>. ‚ÄúIf I collect one new data point at this <span class="math inline">\(x\)</span> value, where will it likely fall?‚Äù</p></li>
</ul>
<p>Notice how the observed data points (black dots) mostly fall within the red bands but often outside the blue bands ‚Äì exactly as they should. The blue bands don‚Äôt try to capture individual observations; they capture the mean trend.</p>
<p><strong>Practical implications:</strong></p>
<ul>
<li>Planning a policy based on expected outcomes? Use credible intervals (blue).</li>
<li>Predicting whether a specific patient will respond? Use prediction intervals (red).</li>
<li>Building a forecast with uncertainty bounds? Use prediction intervals (red).</li>
</ul>
</section>
</section>
<section id="takeaway-from-complex-to-simple" class="level2">
<h2 class="anchored" data-anchor-id="takeaway-from-complex-to-simple">Takeaway: from complex to simple</h2>
<p><strong>Hard part:</strong> compute <span class="math inline">\(p(\theta\mid D)\)</span> with MCMC (explore a high-dimensional space; replace intractable integrals with samples).</p>
<p><strong>Easy part:</strong> treat those samples like columns in a matrix and do arithmetic to move through the stages:</p>
<ul>
<li>Posterior parameters <span class="math inline">\(p(\theta\mid D)\)</span> ‚áí compute the mean response <span class="math inline">\(\mu\)</span> for each draw<br>
</li>
<li>Add observation noise to get posterior predictive draws <span class="math inline">\(p(\tilde{y}\mid D)\)</span><br>
</li>
<li>Summarize these distributions using row-wise statistics: row means give point estimates like <span class="math inline">\(E[\tilde{y}\mid D]\)</span>, row quantiles give credible intervals (from the mean response distribution) and prediction intervals (from the posterior predictive distribution)</li>
</ul>
<p>Keep the stages of Bayesian prediction in mind and everything else becomes mechanical.</p>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Non-Linear Models and Jensen‚Äôs Inequality
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Throughout this post, we‚Äôve focused on Normal linear models where <span class="math inline">\(E[\mu_i|D] = E[\tilde{y}_i|D]\)</span> ‚Äì a convenient mathematical property that makes the math simpler. But what happens with other model families like logistic or Poisson regression?</p>
<p>For models with <strong>non-linear link functions</strong>, this equality breaks down due to <strong>Jensen‚Äôs inequality</strong>: for non-linear functions, the average of the transformed values does NOT equal the transformation of the average. Understanding this is crucial for working correctly with generalized linear models.</p>
<section id="a-concrete-example-logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="a-concrete-example-logistic-regression">A concrete example: Logistic regression</h4>
<div class="cell">
<details open="" class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In logistic regression: probability = logit‚Åª¬π(linear predictor)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate posterior uncertainty on the linear predictor (log-odds scale)</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>log_odds <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fl">1e5</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Two approaches give very different probabilities:</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mean_then_transform =</span> <span class="fu">plogis</span>(<span class="fu">mean</span>(log_odds)),   <span class="co"># logit‚Åª¬π(E[Œ∑]) = 0.50</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">transform_then_mean =</span> <span class="fu">mean</span>(<span class="fu">plogis</span>(log_odds))    <span class="co"># E[logit‚Åª¬π(Œ∑)] ‚âà 0.60</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(results, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>mean_then_transform transform_then_mean 
              0.503               0.501 </code></pre>
</div>
</div>
<p><strong>What‚Äôs happening mathematically:</strong></p>
<p>In logistic regression, probabilities are <span class="math inline">\(\pi = \text{logit}^{-1}(\eta)\)</span> where <span class="math inline">\(\eta\)</span> is the linear predictor.</p>
<ul>
<li><strong>Wrong approach:</strong> Average first, then transform: <span class="math inline">\(\text{logit}^{-1}(E[\eta|D])\)</span> ‚âà 0.50</li>
<li><strong>Right approach:</strong> Transform first, then average: <span class="math inline">\(E[\text{logit}^{-1}(\eta)|D]\)</span> ‚âà 0.60</li>
</ul>
<p>The difference arises because <span class="math inline">\(\text{logit}^{-1}\)</span> is non-linear (it‚Äôs an S-curve). The correct expected probability is 0.60, not 0.50!</p>
</section>
<section id="the-three-tidybayes-functions-for-different-scales" class="level4">
<h4 class="anchored" data-anchor-id="the-three-tidybayes-functions-for-different-scales">The three tidybayes functions for different scales</h4>
<p>When working with non-linear models, you have three options depending on what scale you want to work on:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 34%">
<col style="width: 15%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>What it returns</th>
<th>Scale</th>
<th>Use when‚Ä¶</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>add_linpred_draws()</code></td>
<td>Linear predictor <span class="math inline">\(\eta\)</span></td>
<td>Link scale (log-odds, log-rate, etc.)</td>
<td>You want to work on the linear scale, show effects before transformation, or do arithmetic before transforming</td>
</tr>
<tr class="even">
<td><code>add_epred_draws()</code></td>
<td>Expected value <span class="math inline">\(E[y\mid\eta]\)</span></td>
<td>Response scale (probability, count, etc.)</td>
<td>You want the <strong>mean of the posterior predictive</strong> - this correctly handles the non-linear transformation via integration</td>
</tr>
<tr class="odd">
<td><code>add_predicted_draws()</code></td>
<td>Simulated outcomes <span class="math inline">\(\tilde{y}\)</span></td>
<td>Response scale with noise</td>
<td>You want <strong>actual predicted observations</strong> (0/1 for binomial, integer counts for Poisson, etc.)</td>
</tr>
</tbody>
</table>
<p><strong>The key insight:</strong> <code>add_epred_draws()</code> properly handles Jensen‚Äôs inequality by computing <span class="math inline">\(E[g(\eta)|D]\)</span> where <span class="math inline">\(g\)</span> is the inverse link function. This is NOT the same as <span class="math inline">\(g(E[\eta|D])\)</span>!</p>
</section>
<section id="the-general-lesson" class="level4">
<h4 class="anchored" data-anchor-id="the-general-lesson">The general lesson</h4>
<p>For <strong>any model with non-linear transformations</strong>:</p>
<ul>
<li><strong>For expected values on the response scale:</strong> Use <code>add_epred_draws()</code> - it correctly integrates over parameter uncertainty</li>
<li><strong>For working on the link scale:</strong> Use <code>add_linpred_draws()</code> - useful for visualizing effects or contrasts before transformation<br>
</li>
<li><strong>For prediction intervals or simulating outcomes:</strong> Use <code>add_predicted_draws()</code> - gives you actual draws with observation noise</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical advice
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>For expected predictions</strong> (what we‚Äôve been calling <span class="math inline">\(E[\tilde{y}|D]\)</span>): use <code>add_epred_draws()</code> for <strong>all model families</strong>. It correctly handles the non-linear transformation.</p>
<p><strong>For Normal models only:</strong> <code>add_epred_draws()</code> and averaging the linear predictor happen to give the same answer, which is why we could take shortcuts in the main post. For other families, you must use <code>add_epred_draws()</code>.</p>
</div>
</div>
</section>
<section id="examples-in-other-model-families" class="level3">
<h3 class="anchored" data-anchor-id="examples-in-other-model-families">Examples in other model families</h3>
<p><strong>Logistic regression (binary outcomes):</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>fit_logistic <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(success <span class="sc">~</span> x, <span class="at">data =</span> data, </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># For expected probabilities (CORRECT):</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>mean_probs <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span> </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_epred_draws</span>(fit_logistic) <span class="sc">|&gt;</span>      <span class="co"># Returns probabilities</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_prob =</span> <span class="fu">mean</span>(.epred))   <span class="co"># Average the probabilities</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For effects on the log-odds scale:</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>log_odds_effects <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span> </span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_linpred_draws</span>(fit_logistic) <span class="sc">|&gt;</span>    <span class="co"># Returns log-odds</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_logodds =</span> <span class="fu">mean</span>(.linpred))</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co"># For prediction intervals (actual 0/1 outcomes):</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span> </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_predicted_draws</span>(fit_logistic) <span class="sc">|&gt;</span>  <span class="co"># Returns 0 or 1</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">median_qi</span>(.prediction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Poisson regression (count outcomes):</strong></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Poisson model</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>fit_poisson <span class="ot">&lt;-</span> <span class="fu">stan_glm</span>(count <span class="sc">~</span> x, <span class="at">data =</span> data, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">family =</span> <span class="fu">poisson</span>())</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># For expected counts (CORRECT):</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>mean_counts <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span> </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_epred_draws</span>(fit_poisson) <span class="sc">|&gt;</span>       <span class="co"># Returns expected counts</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_count =</span> <span class="fu">mean</span>(.epred))</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For effects on the log scale:</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>log_effects <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span> </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_linpred_draws</span>(fit_poisson) <span class="sc">|&gt;</span>     <span class="co"># Returns log(counts)</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_log =</span> <span class="fu">mean</span>(.linpred))</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># For prediction intervals (actual integer counts):</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> newdata <span class="sc">|&gt;</span> </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_predicted_draws</span>(fit_poisson) <span class="sc">|&gt;</span>   <span class="co"># Returns integer counts</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">median_qi</span>(.prediction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Key insight:</strong> The workflow stays the same across model families, but you must choose the right function for your question. For expected values on the response scale (the most common use case), <code>add_epred_draws()</code> is always correct.</p>
</section>
</div>
</div>
</div>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li>McElreath‚Äôs <a href="https://xcelab.net/rm/statistical-rethinking/"><em>Statistical Rethinking</em></a> has excellent coverage of posterior prediction and makes these concepts very intuitive</li>
<li>Gelman et al.‚Äôs <a href="http://www.stat.columbia.edu/~gelman/book/"><em>Bayesian Data Analysis</em></a> (Chapter 7) covers posterior predictive checking in detail</li>
<li>The <a href="https://mjskay.github.io/tidybayes/"><code>tidybayes</code> documentation</a> and <a href="https://mjskay.github.io/tidybayes/articles/">vignettes</a> provide great examples of working with posterior draws in a tidy format, including detailed guidance on <code>add_epred_draws()</code> vs <code>add_predicted_draws()</code> vs <code>add_linpred_draws()</code></li>
</ul>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{schreiber2025,
  author = {Schreiber, Stefan},
  title = {Understanding {Bayesian} {Predictions}},
  date = {2025-11-05},
  url = {https://envirostats.ca/posts/2025-11-05-understanding-bayesian-predictions/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-schreiber2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Schreiber, Stefan. 2025. <span>‚ÄúUnderstanding Bayesian
Predictions.‚Äù</span> November 5, 2025. <a href="https://envirostats.ca/posts/2025-11-05-understanding-bayesian-predictions/">https://envirostats.ca/posts/2025-11-05-understanding-bayesian-predictions/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.envirostats\.ca");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2025, EnviroStats Solutions Inc.</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>